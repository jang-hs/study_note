김기현의 자연어 처리 딥러닝 캠프 : 파이토치 편 _4_3



**[병렬 코퍼스 제작 프로세스]**

1. 소스 언어(source language)와 타깃 언어(target language) 사이 단어 사전 준비
2. 단어 사전이 없다면 다음 작업 수행(있다면 7로)
3. 각 언어에 대해 코퍼스 수집 및 정제
4. 각 언어에 대해 단어 임베딩 벡터 구함.
5. MUSE를 통해 단어 레벨 번역기 훈련
6. 훈련된 단어 레벨 번역기를 통해 두 언어 사이의 단어 사전 생성
7. 만들어진 단어 사전을 넣어 Champollion을 통해 기존 수집된 다중 언어 코퍼스 정렬
8. 각 언어에 대해 단어 사전을 적용하기 위해 알맞은 수준의 분절 수행
9. 각 언어 정제 수행
10. Champollion을 사용하여 병렬 코퍼스 생성

  

**[사전 생성]**  

단어 사전 자동 구축(MUSE) : 병렬 코퍼스가 없는 상황에서 사전을 구축하는 방법과 코드 제공. 각 단일 언어 코퍼스를 통해 구축한 언어별 단어 임베딩 벡터에 대해 다른 언어의 임베딩 벡터와 맵핑 시켜 번역(비지도 학습)

  

**[CTK를 활용한 정렬]**

CTK(Champollion Toolkit) : 이중 언어 코퍼스의 문장 정렬 수행. 기존 구축 단어 사전을 사용하거나 자동으로 구축된 단어 사전을 참고하여 문장 정렬

> 참고페이지를 활용하여 dict파일을 만들고, 샘플 영어 문장과 한글 문장파일을 생성해서 실행시키면 되는데 perl 오류가 발생해서 실행시켜보지 못해서 아쉬웠다. 모듈간 충돌이 일어나서 발생한 듯하다.

[설치 사이트](https://github.com/LowResourceLanguages/champollion)

[참고 페이지-NLP with Pytorcy](https://kh-kim.gitbook.io/natural-language-processing-with-pytorch/00-cover-3/05-align)

  

**[서드워드 분절]**

- 단어는 의미를 가진 더 작은 서브 워드들의 조합으로 이루어진다는 가정 하에 적용되는 알고리즘
- 적절한 서브워드 발견 후 해당 단위로 쪼개면 희소성을 효과적으로 줄임
- UNK(unknown) 토근에 대한 효과적 대처
  
  - 기존 훈련 데이터에서 보았던 토근들의 조합으로 만들 수 있음
- BPE(byte pair encoding) 알고리즘을 통한 서브워드 단어 분절(필수 전처리 방법으로 자리잡음)

  

>  [[김기현의 자연어 처리 딥러닝 캠프 : 파이토치 편\]](https://www.aladin.co.kr/m/mproduct.aspx?ItemId=195347339) 을 공부하며 메모한 내용입니다.  



